{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Project 1: Image Filtering and Hybrid Images\n",
    "\n",
    "All projects in this course will be executed within an iPython notebook. Using an IPython notebooks is a convenient way for you to quickly and easily interact with the code. A notebook contains many blocks of code, each of which can be run independently. You can run a cell with ctrl+enter or shift+enter (to move to the next cell).\n",
    "\n",
    "\n",
    "## Part 1: NumPy\n",
    "### Setup\n",
    "Before we get started, we'll do a quick check to ensure you've previously installed the `proj1_code` module by running the command `pip install -e .` in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.utils import load_image, save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that didn't throw an error, then you're good to proceed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from proj1_code.utils import load_image, save_image\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "image1 = load_image('../data/1a_dog.bmp')\n",
    "image2 = load_image('../data/1b_cat.bmp')\n",
    "\n",
    "# display the dog and cat images\n",
    "plt.figure(figsize=(3,3)); plt.imshow((image1*255).astype(np.uint8));\n",
    "plt.figure(figsize=(3,3)); plt.imshow((image2*255).astype(np.uint8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create filter\n",
    "\n",
    "You will first need to implement `create_Gaussian_kernel_1D()`  in `part1.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.part1 import create_Gaussian_kernel_1D\n",
    "ksize = 29\n",
    "sigma = 7\n",
    "kernel_1d = create_Gaussian_kernel_1D(ksize, sigma)\n",
    "plt.imshow(kernel_1d.T) # plot (N,1) column vector as (1,N) row vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run these two simple test cases to check if the implementation seems correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.utils import verify\n",
    "from proj1_unit_tests.test_part1 import (\n",
    "    test_create_Gaussian_kernel_1D,\n",
    "    test_create_Gaussian_kernel_1D_sumsto1,\n",
    "    test_create_Gaussian_kernel_1D_peak\n",
    ")\n",
    "\n",
    "print(verify(test_create_Gaussian_kernel_1D))\n",
    "print(verify(test_create_Gaussian_kernel_1D_sumsto1))\n",
    "print(verify(test_create_Gaussian_kernel_1D_peak))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will need to implement `create_Gaussian_kernel_2D()` (which can use `create_Gaussian_kernel_1D`)  in `part1.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.part1 import create_Gaussian_kernel_2D\n",
    "from proj1_code.utils import verify, PIL_resize\n",
    "from proj1_unit_tests.test_part1 import (\n",
    "    test_create_Gaussian_kernel_2D_sumsto1,\n",
    "    test_create_Gaussian_kernel_2D_peak,\n",
    "    test_gaussian_kernel_2D\n",
    ")\n",
    "\n",
    "cutoff_frequency = 7\n",
    "kernel = create_Gaussian_kernel_2D(cutoff_frequency)\n",
    "\n",
    "# let's take a look at the filter!\n",
    "plt.figure(figsize=(4,4)); plt.imshow(kernel);\n",
    "\n",
    "## Verify that the Gaussian kernel was created correctly\n",
    "print(verify(test_create_Gaussian_kernel_1D_sumsto1))\n",
    "print(verify(test_create_Gaussian_kernel_1D_peak))\n",
    "print(verify(test_create_Gaussian_kernel_2D_sumsto1))\n",
    "print(verify(test_create_Gaussian_kernel_2D_peak))\n",
    "print(verify(test_gaussian_kernel_2D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply filter to image\n",
    "The next two functions you need to implement in this project can also be found in `part1.py`. Start by implementing `my_conv2d_numpy`, which takes both a filter and an image, and returns the filtered image. This code block will use your `my_conv2d_numpy` function to create and display a blurry version of image1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.part1 import (\n",
    "    my_conv2d_numpy,\n",
    "    create_hybrid_image\n",
    ")\n",
    "from proj1_unit_tests.test_part1 import (\n",
    "    test_my_conv2d_numpy_identity,\n",
    "    test_my_conv2d_numpy_ones_filter,\n",
    "    test_my_conv2d_numpy_nonsquare_filter\n",
    ")\n",
    "\n",
    "blurry_image = my_conv2d_numpy(image1, kernel)\n",
    "\n",
    "plt.figure(figsize=(11,6))\n",
    "plt.subplot(1,2,1); plt.imshow(image1)\n",
    "plt.subplot(1,2,2); plt.imshow((blurry_image*255).astype(np.uint8))\n",
    "\n",
    "## Verify that my_conv2d_numpy() was implemented correctly\n",
    "print(verify(test_my_conv2d_numpy_identity))\n",
    "print(verify(test_my_conv2d_numpy_ones_filter))\n",
    "print(verify(test_my_conv2d_numpy_nonsquare_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Filtering\n",
    "\n",
    "Here are a few test cases to help you test `my_conv2d_numpy()`, which you will write. You should verify that you get reasonable output here before using your filtering to construct a hybrid image in `part1.py`. The outputs are all saved and you can include them in your writeup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = load_image('../data/1b_cat.bmp')\n",
    "original_height = test_image.shape[0]\n",
    "original_width = test_image.shape[1]\n",
    "test_image = PIL_resize(test_image, (int(0.7*original_width), int(0.7*original_height)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity filter\n",
    "For the identity filter, the filtering result should look identical to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_filter = np.asarray([[0, 0, 0], [0, 1, 0], [0, 0, 0]])\n",
    "identity_image = my_conv2d_numpy(test_image, identity_filter)\n",
    "plt.imshow(identity_image)\n",
    "done = save_image('../results/part1/identity_image.jpg', identity_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small blur with a box filter\n",
    "This filter should remove some high frequencies. (See the effect on the cat's whiskers, for example.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_filter = np.ones((3,3)) \n",
    "blur_filter /= np.sum(blur_filter)  # making the filter sum to 1\n",
    "blur_image = my_conv2d_numpy(test_image, blur_filter)\n",
    "plt.figure(figsize=(11,6))\n",
    "plt.subplot(1,2,1); plt.imshow(test_image)\n",
    "plt.subplot(1,2,2); plt.imshow(blur_image)\n",
    "done = save_image('../results/part1/blur_image.jpg', blur_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oriented filter (Sobel operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_filter = np.asarray([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])  # should respond to horizontal gradients\n",
    "sobel_image = my_conv2d_numpy(test_image, sobel_filter)\n",
    "\n",
    "# 0.5 added because the output image is centered around zero otherwise and mostly black\n",
    "sobel_image = np.clip(sobel_image+0.5, 0.0, 1.0)\n",
    "plt.figure(figsize=(11,6))\n",
    "plt.subplot(1,2,1); plt.imshow(test_image)\n",
    "plt.subplot(1,2,2); plt.imshow(sobel_image)\n",
    "done = save_image('../results/part1/sobel_image.jpg', sobel_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High pass filter (discrete Laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian_filter = np.asarray([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n",
    "laplacian_image = my_conv2d_numpy(test_image, laplacian_filter)\n",
    "\n",
    "# 0.5 is added because the output image is centered around zero otherwise and mostly black\n",
    "laplacian_image = np.clip(laplacian_image+0.5, 0.0, 1.0)\n",
    "plt.figure(); plt.imshow(laplacian_image)\n",
    "done = save_image('../results/part1/laplacian_image.jpg', laplacian_image)\n",
    "\n",
    "# High pass \"filter\" alternative\n",
    "high_pass_image = test_image - blur_image\n",
    "high_pass_image = np.clip(high_pass_image+0.5, 0.0, 1.0)\n",
    "plt.figure(); plt.imshow(high_pass_image)\n",
    "done = save_image('../results/part1/high_pass_image.jpg', high_pass_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hybrid image\n",
    "Next, implement `create_hybrid_image()`, which takes two images and makes a hybrid image using the low frequency content from one image and the high frequency content from another by applying the Gaussian kernel you defined in `create_Gaussian_kernel_2D()`.\n",
    "\n",
    "Experiment with the value of `cutoff_frequency` for each pair of images in `data/`. For each image pair, replace `cutoff_frequencies.txt` with the best cutoff frequency value you find. The value on line *i* of the text file should correspond to _i_-th image pair. This is an important step for Part 2! Feel free to also experiment with which image in each pair you grab the low frequencies from and which image you grab high frequencies from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.utils import vis_image_scales_numpy\n",
    "from proj1_unit_tests.test_part1 import test_hybrid_image_np\n",
    "\n",
    "low_frequencies, high_frequencies, hybrid_image = create_hybrid_image(image1, image2, kernel)\n",
    "\n",
    "## Verify that results are as expected\n",
    "print(verify(test_hybrid_image_np))\n",
    "\n",
    "vis = vis_image_scales_numpy(hybrid_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,6));\n",
    "plt.subplot(1,2,1); plt.imshow((low_frequencies*255).astype(np.uint8));\n",
    "plt.subplot(1,2,2); plt.imshow(((high_frequencies+0.5)*255).astype(np.uint8));\n",
    "plt.figure(figsize=(20, 20)); plt.imshow(vis);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image('../results/part1/low_frequencies.jpg', low_frequencies)\n",
    "save_image('../results/part1/high_frequencies.jpg', high_frequencies+0.5)\n",
    "save_image('../results/part1/hybrid_image.jpg', hybrid_image)\n",
    "save_image('../results/part1/hybrid_image_scales.jpg', vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: PyTorch \n",
    "\n",
    "Make sure you have specified a cutoff value in `cutoff_frequencies.txt` for each image pair in `data/` before executing the following blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "from proj1_code.part2_datasets import HybridImageDataset\n",
    "from proj1_code.part2_models import HybridImageModel\n",
    "\n",
    "if not os.path.exists('../results/part2/'):\n",
    "        os.makedirs('../results/part2/')\n",
    "        \n",
    "data_root = '../data' # if you're using additional data, make sure to change this to '../additional_data'\n",
    "cf_file = '../cutoff_frequencies.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model & dataset\n",
    "Implement `HybridImageModel` and `HybridImageDataset`, found in `part2_models.py` and `part2_datasets.py`, respectively.\n",
    "\n",
    "In the code documentation, you will see a term called \"batch size\", which we will discuss in later projects and lectures. For now, we are using the default value of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridImageModel()\n",
    "dataset = HybridImageDataset(data_root, cf_file)\n",
    "dataloader = torch.utils.data.DataLoader(dataset)\n",
    "\n",
    "data_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hybrid images\n",
    "This code block will iterate through pairs of images from your dataset and create a hybrid image using the low frequency content from one image and the high frequency content from another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    image_a, image_b, cutoff_frequency = next(data_iter)\n",
    "    low_frequencies, high_frequencies, hybrid_image = model(image_a, image_b, cutoff_frequency)\n",
    "    \n",
    "    # saves low frequencies, high frequencies, and hybrid image of each pair of images\n",
    "    torchvision.utils.save_image(low_frequencies, '../results/part2/%d_low_frequencies.jpg' % i)\n",
    "    torchvision.utils.save_image(high_frequencies+0.5, '../results/part2/%d_high_frequencies.jpg' % i)\n",
    "    torchvision.utils.save_image(hybrid_image, '../results/part2/%d_hybrid_image.jpg' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verify that the results are correct\n",
    "from proj1_unit_tests.test_part2 import (\n",
    "    test_low_freq_sq_kernel_pytorch, \n",
    "    test_high_freq_sq_kernel_pytorch,\n",
    "    test_hybrid_image_pytorch\n",
    ")\n",
    "\n",
    "## Verify that the Pytorch results are as expected\n",
    "print(verify(test_low_freq_sq_kernel_pytorch))\n",
    "print(verify(test_high_freq_sq_kernel_pytorch))\n",
    "## Verify that the Pytorch hybrid images are created correctly\n",
    "print(verify(test_hybrid_image_pytorch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid image timing comparison\n",
    "Here, we will compare the runtime of creating hybrid images using your NumPy implementation to using your PyTorch implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "image1 = load_image('../data/1a_dog.bmp')\n",
    "image2 = load_image('../data/1b_cat.bmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing Part 1. Notice that we explicitly include `create_Gaussian_kernel()_2D` in the timing of Part 1 but not Part 2. This is because the function is already being called (and therefore timed) inside the forward pass of `HybridImageModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "cutoff_frequency = 7\n",
    "kernel = create_Gaussian_kernel_2D(cutoff_frequency)\n",
    "low_frequencies, high_frequencies, hybrid_image = create_hybrid_image(image1, image2, kernel)\n",
    "end = time.time() - start\n",
    "print('Part 1: {:.3f} seconds'.format(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridImageModel()\n",
    "\n",
    "start = time.time()\n",
    "low_frequencies, high_frequencies, hybrid_image = model(image_a, image_b, torch.Tensor([cutoff_frequency]))\n",
    "end = time.time() - start\n",
    "print('Part 2: {:.3f} seconds'.format(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understanding input/output shapes in PyTorch\n",
    "Up until this point, we have produced a filtered output that has the same dimensions as the input image. Let's explore how you can stack multiple filters, apply them in a single operation using your `my_conv2d_pytorch` implementation in `part3.py`, and see how it affects the output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_unit_tests.test_part3 import test_my_conv2d_pytorch\n",
    "\n",
    "# Verify that feature maps are correctly created\n",
    "print(verify(test_my_conv2d_pytorch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_image('../data/1a_dog.bmp')\n",
    "\n",
    "# turn HW image into CHW, where C=1 for grayscale\n",
    "image = np.transpose(image, (2,0,1))\n",
    "print('Image has shape: ', image.shape)\n",
    "image = torch.from_numpy(image).unsqueeze(0) #convert to tensor and add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.part3 import my_conv2d_pytorch\n",
    "\n",
    "# stack all the test filters along the channel dimension\n",
    "filter_bank = np.stack(\n",
    "    [\n",
    "        [identity_filter], \n",
    "        [blur_filter],\n",
    "        [sobel_filter], \n",
    "        [laplacian_filter],\n",
    "        [identity_filter], \n",
    "        [blur_filter],\n",
    "        [sobel_filter], \n",
    "        [laplacian_filter],\n",
    "        [identity_filter], \n",
    "        [blur_filter],\n",
    "        [sobel_filter], \n",
    "        [laplacian_filter]\n",
    "    ])\n",
    "print('Filter bank has shape: ', filter_bank.shape)\n",
    "\n",
    "filter_bank = torch.from_numpy(filter_bank).float()\n",
    "# Run the image filtering operation\n",
    "feature_maps = my_conv2d_pytorch(image, filter_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_maps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib requires numpy arrays with a particular shape format (h, w, c) for visualizing images. Here, we split and convert `feature_maps` to the appropriate shape arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(4):  # we are stacking 4 filters in the filter bank\n",
    "    print('Visualization {}:'.format(idx))\n",
    "    feature_map = feature_maps[0, [idx, idx+4, idx+8], :, :]\n",
    "    # (c, h, w) --> (h, w, c) for matplotlib visualization purposes\n",
    "    feature_map = np.transpose(feature_map.numpy(),(1,2,0))\n",
    "    plt.figure()\n",
    "    offset = 0 #offset for vis purposes. sobel and laplace use .5\n",
    "    if idx > 1:\n",
    "        offset = .5\n",
    "    plt.imshow(np.clip(feature_map+offset,0,1))\n",
    "    plt.show()\n",
    "    save_image('../results/part3/visualization_{}.jpg'.format(idx), feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}